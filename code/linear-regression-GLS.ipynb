{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tools.tools import add_constant\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building GLS model for each country's status\n",
    "\n",
    "With so many autocorrelation the best solution should be to apply the GLS method.\n",
    "\n",
    "We saw when using OLS model, the performance of the model for specific group of countries based on their status was better (AIC is lower evein if R2 was smaller as well but still acceptable), so we should applied this GLS model for each country's status. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Developed countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev = pd.read_csv('../data/expectancy_dev.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dev = df_dev.life_expectancy\n",
    "X_dev = df_dev.drop(columns=['life_expectancy','status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First step is to get the residuals using the OLS model\n",
    "\n",
    "ols_resid = sm.OLS(y_dev,add_constant(X_dev)).fit().resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a linear regression between each residuals and the previous one\n",
    "\n",
    "resid_fit = sm.OLS(ols_resid.values[1:], ols_resid.values[:-1]).fit()\n",
    "rho = resid_fit.params\n",
    "rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import toeplitz\n",
    "order = toeplitz(np.arange(X_dev.shape[0]))\n",
    "sigma = rho**order\n",
    "sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gls_model = sm.GLS(y_dev, X_dev, sigma=sigma)\n",
    "gls_results = gls_model.fit()\n",
    "gls_results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Phacking and model improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refefining the phacking function to drop the column using GLS model\n",
    "\n",
    "def gls_phacking(column,X,y):\n",
    "    global sigma\n",
    "    \n",
    "    if column:\n",
    "        X=X.drop(column,axis=1)\n",
    "    \n",
    "    gls_model = sm.GLS(y, X, sigma=sigma).fit()\n",
    "    \n",
    "    display(gls_model.summary())\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of columns to be dropped tp keep track on deleted columns\n",
    "dropped_cols = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_cols.append('polio')\n",
    "dropped_cols[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping parameters with high pvalue for model improvement\n",
    "\n",
    "X_dev = gls_phacking(dropped_cols[-1],X_dev,y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Checking Multicollinearity (assumptions)\n",
    "\n",
    "Checking Variance Inflation Factor for parameters. The threshold is 10, if the parameters is above 10 we should drop the parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor as VIF\n",
    "\n",
    "def drop_check_vif(column, X):\n",
    "    if column:\n",
    "        X=X.drop(column, axis=1)\n",
    "    vifs=pd.Series([VIF(X.values,i) for i in range(X.shape[1])],index=X.columns)\n",
    "    display(vifs[vifs>10])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_cols.append('schooling')\n",
    "dropped_cols[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev = drop_check_vif(dropped_cols[-1], X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rebuilding the model outside of the function\n",
    "gls_model = sm.GLS(y_dev, X_dev, sigma=sigma)\n",
    "gls_results = gls_model.fit()\n",
    "gls_results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "I should check the assumptions for GLS, not sure VIF needs to be checked or maybe the GLS model\n",
    "should be built after working on the first OLS model and satified the assumptions except for autocorrelation.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
