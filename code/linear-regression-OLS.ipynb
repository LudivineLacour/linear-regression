{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tools.tools import add_constant\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/life_expectancy_data_cleaned.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build OLS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.life_expectancy\n",
    "X = df.drop(columns='life_expectancy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=sm.OLS(y,add_constant(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit=model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P-Hacking and model improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Defining a function to drop the column and return the new model\n",
    "\n",
    "def phacking(column,X,y):\n",
    "    \n",
    "    if column:\n",
    "        X=X.drop(column,axis=1)\n",
    "    \n",
    "    model=sm.OLS(y,add_constant(X)).fit()\n",
    "    \n",
    "    display(model.summary())\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_cols = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_cols.append('alcohol')\n",
    "dropped_cols[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=phacking(dropped_cols[-1],X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Summary of the model:\n",
    "\n",
    "The pvalue of F-statistic is under 0.05 so we have small chances of being wrong \n",
    "if we assume the parameters are not equals to 0 at the same time.\n",
    "\n",
    "All our parameters have a pvalue under 0.05 that means we have small chances of being wrong is by keeping them.\n",
    "\n",
    "R-squared value is high (81.7%) and increased a slightly when we removed the parameters.\n",
    "\n",
    "AIC and BIC are almost zero so we can assume they are low. \n",
    "\n",
    "We still have some warnings displayed at the end of the model, especially about multicollinearity,\n",
    "so we should check our assumptions and transform our data if needed.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick check of OLS assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Re-building the model outside of the function \n",
    "\n",
    "model = sm.OLS(y,add_constant(X))\n",
    "model_fit=model.fit()\n",
    "model_fit.save('../models/fitted_model_1.pickle')\n",
    "model_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the predictions\n",
    "\n",
    "y_pred=model_fit.predict(add_constant(X))\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if predictions seems to be linear\n",
    "plt.scatter(y,y_pred)\n",
    "plt.title('Linearity of predictions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking residuals\n",
    "(y-y_pred).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking how residuals are displayed\n",
    "plt.plot(y-y_pred)\n",
    "plt.title('Residuals Variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resid=y-y_pred\n",
    "sns.distplot(resid)\n",
    "plt.title('Distribution of residuals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Summary of first checking: \n",
    "\n",
    "The predictions seems to be linear even if we can still see some outliers at the begining. \n",
    "\n",
    "The average of residuals value is almost 0 so our errors seems to be minimized. \n",
    "In the meantime, we can see the noise is not so regular and we can clearly identify outliers. \n",
    "\n",
    "Then, we can see residuals look like normally distributed but we should still confirm that with the hypothesis.\n",
    "\n",
    "Finally, we should check the assumptions mathematically. \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual check of assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Multicollinearity\n",
    "\n",
    "Checking Variance Inflation Factor for parameters. The threshold is 10, if the parameters is above 10 we should drop the parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor as VIF\n",
    "\n",
    "def drop_check_vif(column, X):\n",
    "    if column:\n",
    "        X=X.drop(column, axis=1)\n",
    "    vifs=pd.Series([VIF(X.values,i) for i in range(X.shape[1])],index=X.columns)\n",
    "    display(vifs[vifs>10])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = drop_check_vif('',X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteration on model-1\n",
    "\n",
    "Following the global check of assumptions on model-1 ([assumptions-model-1.ipynb](assumptions-model-1.ipynb)), it doesn't meet the assumptions so we should iterate to create a new model and check again the assumptions. \n",
    "\n",
    "Possible iterations:\n",
    "* removing infant_deaths and under-five_deaths params because they are the most correlated to others\n",
    "* removing polio, diphtheria and schooling params if they are still above 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_cols=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_cols.append('schooling')\n",
    "dropped_cols[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = drop_check_vif(dropped_cols[-1],X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-building the model outside of the function\n",
    "\n",
    "model = sm.OLS(y,add_constant(X2))\n",
    "model_fit=model.fit()\n",
    "model_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving as model-2\n",
    "\n",
    "model_fit.save('../models/fitted_model_2.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteration on model-2\n",
    "By checking the assumptions on model-2 ([assumptions-model-2.ipynb](assumptions-model-2.ipynb)), they are still no met.\n",
    "\n",
    "Possible iterations:\n",
    "* find a way to make the measles parameter follow linearity\n",
    "* perform a non-linear transformation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3 = X2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of columns dropped to keep track of their dropping\n",
    "\n",
    "dropped_cols=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_cols.append('')\n",
    "dropped_cols[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking again the model, the R2 value and if parameters are still relevant.\n",
    "\n",
    "X3=phacking('',X3,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the distribution of each parameters except for dummies because it is not relevant\n",
    "\n",
    "fig,axs=plt.subplots(2,4,figsize=(17,6))\n",
    "\n",
    "for i in range(X3.shape[1]-2):\n",
    "    ax = axs[i//4,i%4]\n",
    "    sns.distplot(X3.iloc[:,i],ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing a non-linear transformation through standardization of data except for dummies\n",
    "fig,axs=plt.subplots(2,4,figsize=(17,6))\n",
    "\n",
    "for i in range(X3.shape[1]-2):\n",
    "    ax = axs[i//4,i%4]\n",
    "    sns.distplot(((X3.iloc[:,i]-X3.iloc[:,i].mean())/X3.iloc[:,i].std()),ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing a logarithmic non-linear transformation except for dummies because it is not relevant\n",
    "\n",
    "fig,axs=plt.subplots(2,4,figsize=(17,6))\n",
    "\n",
    "for i in range(X3.shape[1]-2):\n",
    "    ax = axs[i//4,i%4]\n",
    "    sns.distplot(((X3.iloc[:,i]+0.000000001).apply(np.log)),ax=ax);\n",
    "\n",
    "fig.suptitle('Logarithmic transformation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-building the model outside of the function\n",
    "\n",
    "model = sm.OLS(y,add_constant(X3))\n",
    "model_fit=model.fit()\n",
    "model_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving as model-3\n",
    "model_fit.save('../models/fitted_model_3.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Conclusion on the thrid iteration: \n",
    "\n",
    "We can see that data is not really normmaly distributed and a basic non-linear transformation is not enough\n",
    "because we can see a lot a data with around 0 value. \n",
    "\n",
    "=> We should rather split our data into set of common behaviours, \n",
    "such as status of countries (Developed, Developing, Lead Developed).\n",
    "\n",
    "After creating a model for each country status, we check if:\n",
    "- meales is still violating linearity\n",
    "- autocorrelation is still present\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a model for each status of country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Model for Developed countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev = pd.read_csv('../data/expectancy_dev.csv')\n",
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_y = df_dev.life_expectancy\n",
    "dev_X = df_dev.drop(columns=['life_expectancy','status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_model = sm.OLS(dev_y,add_constant(dev_X))\n",
    "dev_model_fit = dev_model.fit()\n",
    "dev_model_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_cols = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_cols.append('measles')\n",
    "dropped_cols[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_X = phacking(dropped_cols[-1],dev_X,dev_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rebuilding the model outside of the function and saving for assumptions check\n",
    "\n",
    "dev_model = sm.OLS(dev_y,add_constant(dev_X))\n",
    "dev_model_fit = dev_model.fit()\n",
    "dev_model_fit.save('../models/dev-fitted-model-1.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Iteration on dev-model-1\n",
    "By checking the assumptions on dev-model-1 ([assumptions-dev-model-1.ipynb](assumptions-dev-model-1.ipynb)), they are still not met.\n",
    "\n",
    "Possible iterations:\n",
    "* removing hiv/aids, infant_deaths and under-five_deaths params because they have VIF > 10\n",
    "* find a way to make the bmi, total_expenditure, diphtheria parameters follow linearity\n",
    "* correct the autocorrelation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_X2 = dev_X.copy()\n",
    "print(dev_X2.shape)\n",
    "dev_X2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating list of columns dropped to keep track\n",
    "dropped_cols = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_cols.append('diphtheria')\n",
    "dropped_cols[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_X2 = drop_check_vif(dropped_cols[-1],dev_X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_X2 = phacking('under-five_deaths',dev_X2,dev_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.OLS(dev_y,add_constant(dev_X2))\n",
    "model_fit=model.fit()\n",
    "model_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion \n",
    "\n",
    "We ended up with a better performance model because AIC is much lower than the model built with all countries. \n",
    "\n",
    "But we still have the same issues on assumptions about autocorrelation and exegoneity of residuals (normal fistribution of them).\n",
    "\n",
    "To fix the first assumptions, we should try to apply Generalized Least Squares (GLS) model which better fit with dataset having a lot of correlation as we actually have in our dataset. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
